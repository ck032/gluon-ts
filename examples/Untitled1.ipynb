{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is the sample code to check the environment for running GluonTS.\n",
    "\n",
    "Before running sample.py, please check requirement.txt and install required packages.\n",
    "\n",
    "Sample.py includes two deep learning models, DeepAR and MQCNN.\n",
    "\n",
    "Papers about two models for time series forecasting:\n",
    "\n",
    "DeepAR: https://arxiv.org/pdf/1704.04110.pdf\n",
    "\n",
    "MQCNN: https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_conv/ (wavenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "num_batches_per_epoch = 10\n",
    "dataset_name = \"m4_hourly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(dataset_name,regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use GPU, please set ctx=\"gpu(0)\"ã€€/ ctx=\"cpu\"\n",
    "estimators = [\n",
    "    partial(\n",
    "        DeepAREstimator,\n",
    "        trainer=Trainer(\n",
    "            ctx=\"gpu(0)\",\n",
    "            epochs=epochs,\n",
    "            num_batches_per_epoch=num_batches_per_epoch\n",
    "        )\n",
    "    ),\n",
    "    partial(\n",
    "        MQCNNEstimator,\n",
    "        trainer=Trainer(\n",
    "            ctx=\"gpu(0)\",\n",
    "            epochs=epochs,\n",
    "            num_batches_per_epoch=num_batches_per_epoch\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for estimator in estimators:\n",
    "    estimator = estimator(\n",
    "        prediction_length=dataset.metadata.prediction_length,\n",
    "        freq=dataset.metadata.freq\n",
    "    )\n",
    "    predictor = estimator.train(dataset.train)\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset.test, predictor=predictor, num_eval_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(dataset.test)\n",
    "    )\n",
    "\n",
    "    eval_dict = agg_metrics\n",
    "    eval_dict[\"dataset\"] = dataset_name\n",
    "    eval_dict[\"estimator\"] = type(estimator).__name__\n",
    "    results.append(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "sub_df = df[\n",
    "    [\n",
    "        \"dataset\",\n",
    "        \"estimator\",\n",
    "        \"mean_wQuantileLoss\",\n",
    "    ]\n",
    "]\n",
    "print(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
